{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36826f19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02f9c2708fe32121c26e55a4b57c5dbc",
     "grade": false,
     "grade_id": "cell-99711b20314f6d4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Summary Assignment for Module 6\n",
    "<blockquote>This is an assignment in a Jupyter notebook which will be autograded. To avoid autograder errors, please do not add or delete any cells. Also, <b>run all cells even if they are hidden</b> and not requiring any input from you. You may add additional calulations or print statements to any cell to help you see the current values of variables you may be working with.\n",
    "</blockquote>\n",
    "\n",
    "**Rounding Error:** Ideally, your answers will be given from a direct Python calculation. For example, given a $2 \\times 2$ array $A$, if you are asked to multiply the $(1,3)$ entry with the $(2,2)$ entry and to store the result in a variable `x`, you would type\n",
    "\n",
    "<code>x = A[1,3]*A[2,2]</code>\n",
    "\n",
    "(Recall that Python uses zero-based indexing so the $(1,3)$ entry is actually coming from the second row.)\n",
    "\n",
    "However, if you compute `A[1,3]*A[2,2]` and see `0.23719445178`, you could choose to type out the answer as, for example,\n",
    "\n",
    "<code>x = 0.23719445</code>\n",
    "\n",
    "<u>as long as you keep at least 3 decimal places of accuracy</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625dd279",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2178d847b4ec2de22e3913ab1c52d78",
     "grade": false,
     "grade_id": "cell-cd0b3c538b25b950",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to import the NumPy library with the name \"np\" and a\n",
    "# testing library that will be used by the autograder\n",
    "import numpy as np\n",
    "import numpy.testing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76465b49",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9000acd328ee1a0aa3588d7e92523fd2",
     "grade": false,
     "grade_id": "cell-0cdcd2da2a16e9f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem: Marvin in a Maze\n",
    "\n",
    "Suppose that Marvin the rat is in a maze, with 14 cells, depicted below. Marvin continuously wanders the maze in search of food. There is an endless supply of cheese in the maze in cell 3 and an endless supply of lettuce in cell 14. There are two blocked cells, indicated in blue-green with diagonal stripes. \n",
    "\n",
    "<br>\n",
    "<img src=\"rat2_mdp.png\" width=\"400\"> <br>\n",
    "\n",
    "In cells other than 3, 10, and 14, Marvin can choose to go up, down, left, or right. Attempting to go off the maze and into a blocked cell will leave Marvin's position unchanged for the next time step. Upon arriving in cell 3, Marvin will eat some cheese but, in the next move, he will teleport to cell 8 with probability 1.  Upon arriving in cell 14, Marvin will eat some lettuce but, in the next move, he will teleport to cell 12 with probability 1. These teleportations will always happen and there are no policy moves to be learned for exiting cells 3 and 14. Although Marvin is happy to have found some food, he always wants more and will continue wander indefinitely!\n",
    "\n",
    "When moving out of cell 10, with probability 1/2, Marvin will teleport to cell 5. The rest of the time, he will choose from neighboring cells according to the policy he is learning on his journey.\n",
    "\n",
    "Rewards are as follows.\n",
    "\n",
    "<ul>\n",
    "    <li> If Marvin enters cell 3, he receives a reward of +5 because cheese is great!</li>\n",
    "    <li> If he enters cell 14, he receives a reward of +2 because lettuce is better than nothing.</li>\n",
    "    <li> If he attempts to go off the grid or into a blocked cell, he receives a reward of -1.</li>\n",
    "    <li> When he enters any other cells, either by walking or teleportation, he receives a reward of 0.</li>\n",
    "</ul>\n",
    "\n",
    "Using a discount factor of $0.95$, find the optimal policy for Marvin's movements. Begin with a \"mostly random walk policy\" where up, down, left, and right movements, are equally likely unless Marvin is in a special cell.\n",
    "\n",
    "Special Transition Probability Examples:\n",
    "<ul>\n",
    "   <li>If he is in cell 1, he will move to the right to cell 2 with probability 1/4, he will move down to cell 5 with probability 1/4, and he will stay in cell 1 with probability 1/2, due to two possible illegal moves (up and left), each with probability 1/4, that bounce him back to cell 1.</li>\n",
    "    <li> If he is in cell 10, he will teleport to cell 5 with probability 1/2. With probability 1/2, he will attempt to move up, down, left, or right. Moving down will bounce him back to cell 10. Thus, the transition probabilities out of cell 10 under this \"mostly random walk\" policy are\n",
    "        <br><br>\n",
    "        $$\n",
    "        \\begin{array}{lcl}\n",
    "        p(10,5) &=& 1/2\\\\\n",
    "        p(10,6) &=& (1-1/2)(1/4) = 1/8\\\\\n",
    "        p(10,9) &=& (1-1/2)(1/4) = 1/8\\\\\n",
    "        p(10,10) &=& (1-1/2)(1/4) = 1/8 \\,\\,\\, \\mbox{(bounce off of blocked cell)}\\\\\n",
    "        p(10,11) &=& (1-1/2)(1/4) = 1/8\n",
    "        \\end{array}\n",
    "        $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13cb35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6818568da2df994961e7ccb27d1e3136",
     "grade": false,
     "grade_id": "cell-bbf008748cf4556f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<hr>\n",
    "<b>Part A)</b> In the next several cells, we will begin the solution towards finding the optimal policy for Marvin to maximize his expected rewards over the time. <b>Fair warning-- there is going to be a problem for you to fix</b> so pay attention to what is in each cell you are asked to run!\n",
    "\n",
    "<hr>\n",
    "We begin by setting the discount factor and defining the rewards vector. For example, the reward associated with Marving being in state 2 is\n",
    "\n",
    "$$\n",
    "r(s_{2}) = \\frac{1}{4}(-1) + \\frac{1}{4}(-1)+\\frac{1}{4}(0)+\\frac{1}{4}(5) = \\frac{3}{4}.\n",
    "$$\n",
    "\n",
    "These terms are associated with moves up, down, left, and right, respectively.\n",
    "\n",
    "As a second example, the reward associated with Marvin being in state 3 is\n",
    "\n",
    "$$\n",
    "r(s_{3}) = (1)(0) = 0\n",
    "$$\n",
    "\n",
    "because, once in state 3, he will teleport to state 8 with probability 1 and there is no reward for making this move.\n",
    "\n",
    "Does this seem right to you? Isn't state 3 a \"high value state\" because it contains the cheese? Rewards and the state values are different things, so let's proceed for now.\n",
    "\n",
    "In the next cell, we set up the full rewards vector. You may want to try one or two more rewards computations of your own and check them against the corresponding elements in the given rewards vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398e5cff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1d174c81567662b852ca17f30af84ab",
     "grade": false,
     "grade_id": "cell-e9fc0953bb5a33c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the discount factor\n",
    "gamma = 0.95\n",
    "\n",
    "# Define the rewards vector \n",
    "r = np.array([-1/2,3/4,0,3/4,-1/2,1,-1/4,-1/4,-1/4,-1/8,1/4,-1/2,-1/2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028e34a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38f7d060440708de5aa85dcd27b5860f",
     "grade": false,
     "grade_id": "cell-ffcda2bdbede2415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We now set up the state transition probabilities under the \"mostly random walk\" policy. For example, when in state 1, Marvin will attempt to go up, down, left, or right with probability 1/4 each. Moves up or to the left, will bounce him back to cell 1. Thus, when in state 1, Marvin will stay in state 1 with probability 1/2 or move to either state 2 or 5 with probability 1/4 each.\n",
    "\n",
    "Pick a couple more rows and check the matrix values given in the next cell before running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eda4e61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4651f973c8b359f0fe3b9b1bed889d9d",
     "grade": false,
     "grade_id": "cell-152a42cd16bb94be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the P matrix. Don't forget to use zero-based indexing! \n",
    "P = np.zeros((14,14))\n",
    "P[0,[0,1,4]] = np.array([0.5,0.25,0.25])\n",
    "P[1,[0,1,2]] = np.array([0.25,0.5,0.25])\n",
    "P[2,7] = 1\n",
    "P[3,[2,3,6]] = np.array([0.25,0.5,0.25])  \n",
    "P[4,[0,4,7]] = np.array([0.25,0.5,0.25])\n",
    "P[5,[2,5,6,9]] = 0.25\n",
    "P[6,[3,5,6,10]] = 0.25\n",
    "P[7,[4,7,8,11]] = 0.25\n",
    "P[8,[7,8,9,12]] = 0.25\n",
    "P[9,[4,5,8,9,10]] = np.array([0.5,0.125,0.125,0.125,0.125])\n",
    "P[10,[6,9,10,13]] = 0.25\n",
    "P[11,[7,11,12]] = np.array([0.25,0.5,0.25])\n",
    "P[12,[8,11,12]] = np.array([0.25,0.25,0.5])\n",
    "P[13,11] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bd1ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98529ebd13d0d9fd91a4cde54bd76d9f",
     "grade": false,
     "grade_id": "cell-18fe92723a6ada89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We are now ready to find the state value function $v_{\\pi}(s)$ for all 14 states. We will use the equation\n",
    "\n",
    "$$\n",
    "\\vec{v}_{\\pi} = (I-\\gamma {\\bf{P}})^{-1} \\vec{r}_{\\pi}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e1c961",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea28b11f8b2af9248c5dff1a11bbcfda",
     "grade": false,
     "grade_id": "cell-9d7c572a320d687c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a 14x14 identity matrix\n",
    "ident = np.identity(14)\n",
    "\n",
    "# Compute the state value function\n",
    "v = np.matmul(np.linalg.inv(ident-gamma*P),r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f455da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eee3cca235fa617452686d58e5cb1c02",
     "grade": false,
     "grade_id": "cell-0e0b0ff6b89fc4f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.59180767, -3.86458674, -6.10885775, -3.06387102],\n",
       "       [-6.39098811,         nan, -3.50158532, -3.8218045 ],\n",
       "       [-6.43037658, -6.20745252, -5.52179588, -4.65191601],\n",
       "       [-6.993821  , -6.92438564,         nan, -6.64412995]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For easier visualization, will organize values into a matrix but\n",
    "# first need to fill in those blocked cells with something\n",
    "# We will use \"np.nan\" which stands for \"not a number\"  but we could choose \n",
    "# anything distinguishable like -99.9999.\n",
    "# Recall that v[start:stop] will return v values with indices from \"start\"\n",
    "\n",
    "v_visual = np.concatenate((v[0:5],[np.nan],v[5:13],[np.nan],v[13:14]))\n",
    "v_visual.reshape((4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52c1f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e2a444d5b910de22b39c4c8cd96b768",
     "grade": false,
     "grade_id": "cell-4cd69b87a50d0afd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Consider writing down the new greedy policy (the grid with arrows determined by the value vector) on paper, for your reference. Remember, you do not need arrows in cells 3 or 14 because the movement there is always deterministic teleportation. Do you see a problem? The cheese and lettuce states (cells 3 and 14) seem like they should be high value states, but they appear to have low values when compared to neighboring cells. Indeed, your policy \"arrow\" grid should, at this point, appear to want to send Marvin to cell 2 when he is in cell 1 and to send Marvin to cell 1 when he is in cell 2! He is not being pushed towards the lettuce and cheese at all from these states! What went wrong here?\n",
    "\n",
    "Answer: The problem is with the rewards structure. As noted, the reward associated being in state 3 (the \"cheese state\") is 0 because it is a function of what Marvin can get when he moves out of the cheese state and not into it. To fix this, we will change the rewards structure so that \n",
    "\n",
    "<ul>\n",
    "    <li>Marvin gets nothing for entering cell 3 but gets the reward of +5 when teleporting out.</li>\n",
    "    <li> He will get nothing for entering cell 14 but gets the reward of +2 when teleporting out.\n",
    "</ul>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac41246",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e631ed07f1528debb7f88c33152f5fa4",
     "grade": false,
     "grade_id": "cell-c296698b75b12e15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Part B)</b> In the next cell, redefine the rewards vector to reflect the changes to the rewards given at the end of the previous cell. Call your rewards vector <code>r_b</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "577058ad",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33207aaa1fafea4e139d231aa396e307",
     "grade": false,
     "grade_id": "cell-24fcabc26c5a8001",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the rewards vector\n",
    "r_b = np.array([0,0,5,0,0,0,0,0,0,0,0,0,0,2])\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1039c80",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8374b6764a790913e0de5fd97e3d0340",
     "grade": true,
     "grade_id": "cell-1e2361ed30642675",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell (Run this cell!)\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e3a03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de56cab7642630e9abbbb37bef35aedc",
     "grade": false,
     "grade_id": "cell-915be8db2d03e54f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, we define the transition probability matrix ${\\bf{P}}$. We will call it P_b because it is the transition matrix being used in part (b) of this exercise. However, we are just restarting the problem with a better rewards structure and this does not represent a policy iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1adb978",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "049285fd55435b8e2f6331d8fed13358",
     "grade": false,
     "grade_id": "cell-c2ec4edb3b6c08ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the P matrix \n",
    "P_b = P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe9609",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da45055032f6ca908d8bb02e4ffdea9f",
     "grade": false,
     "grade_id": "cell-8c16b3b9d4106dbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, compute the state value function v for all states. Call the vector of values v_b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e737ac5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a47964e9072957e5c5a6a71f6e476264",
     "grade": false,
     "grade_id": "cell-d525b82b05eabced",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define v\n",
    "I = np.eye(14)\n",
    "v_b = np.linalg.inv(I - gamma * P) @ r_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e74478e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "308c56811a75fc2d092fe86be731a803",
     "grade": true,
     "grade_id": "cell-35109d70b462e34e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell (Run this cell!)\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f532f130",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "139975a3077a25ba61ccb5d3eb45964c",
     "grade": false,
     "grade_id": "cell-57a6499ca963affc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.84510933,  0.28520761,  0.31767351,  1.41311562],\n",
       "       [-4.4691335 ,         nan,  0.33122489, -0.35183899],\n",
       "       [-4.92876472, -4.5809419 , -3.11295461, -1.82129726],\n",
       "       [-5.72122186, -5.61288361,         nan, -3.43516077]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to better visualize v_b in terms of grid neighboring state values.\n",
    "v_visual = np.concatenate((v_b[0:5],[np.nan],v_b[5:13],[np.nan],v_b[13:14]))\n",
    "v_visual.reshape((4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85732913",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b209a24fb55ea1bdd67955c58ef4fd3e",
     "grade": false,
     "grade_id": "cell-5dc6b767233537b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which of the follow grids with arrows represents the greedy policy at this point? The answer is either 1, 2, 3, or 4. Store your answer in the next cell in a variable called <code>policy_b</code>.\n",
    "\n",
    "<br>\n",
    "<img src=\"four_policies_b.png\" width=\"700\"> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed12b35",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9d3fcccc861700d43b0d75d174753a2",
     "grade": false,
     "grade_id": "cell-2aabf6233e5d882d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "policy_b = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c5a7e30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6d07b116ec47205f5248e0a0a2329d4",
     "grade": true,
     "grade_id": "cell-54e690dc6a992b42",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell (Run this cell!)\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffbda4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "adb2016615594bdcf3851810917bbfa2",
     "grade": false,
     "grade_id": "cell-edc720e7854e3787",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Part C)</b> Let's continue through another policy iteration. In the next cell, enter the next iteration of the rewards vector. Call this r_c (This is the second iteration of the rewards vector but we are calling it r.c because we are in part (c) of this problem.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8ca9d63",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ccbed6ed8bb67c1c59dc713d03bbddb",
     "grade": false,
     "grade_id": "cell-c76c746a51d45f86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the rewards vector\n",
    "r_c = np.array([0,0,5,0,0,0,0,0,0,0,0,0,0,2])\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17e818b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6135364b75e6d55efb6bccb0b0abeaa7",
     "grade": true,
     "grade_id": "cell-ee2ad10f6abe7969",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell (Run this cell!)\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850106ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82aa6fa7af45eca9c1264e32bcf5a5fa",
     "grade": false,
     "grade_id": "cell-c8ca57b34234b774",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, define the transition probability matrix ${\\bf{P}}$. Call this matrix P_c. You can copy and paste the code to define the original ${\\bf{P}}$ to get you started, but you will have to make changes. Don't forget that, if Marvin is in cell 10, he will always have a possibility of teleporting to cell 5 with probability 1/2. With probability 1/2, he will follow the policy that you picked out for policy_b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd770908",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c10fdf21363042090493bae984ac7f8",
     "grade": false,
     "grade_id": "cell-709aa3f60b0a90c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the P matrix. Don't forget to use zero-based indexing! \n",
    "\n",
    "P_c = np.zeros((14,14))\n",
    "\n",
    "# Deterministic moves for non-special states\n",
    "# state 1 -> 2\n",
    "P_c[0,1] = 1.0\n",
    "\n",
    "# state 2 -> 3\n",
    "P_c[1,2] = 1.0\n",
    "\n",
    "# state 3: teleport to 8\n",
    "P_c[2,7] = 1.0\n",
    "\n",
    "# state 4 -> 3\n",
    "P_c[3,2] = 1.0\n",
    "\n",
    "# state 5 -> 1\n",
    "P_c[4,0] = 1.0\n",
    "\n",
    "# state 6 -> 3\n",
    "P_c[5,2] = 1.0\n",
    "\n",
    "# state 7 -> 4\n",
    "P_c[6,3] = 1.0\n",
    "\n",
    "# state 8 -> 9\n",
    "P_c[7,8] = 1.0\n",
    "\n",
    "# state 9 -> 10\n",
    "P_c[8,9] = 1.0\n",
    "\n",
    "# state 10: 1/2 teleport to 5, 1/2 move up to 6\n",
    "P_c[9,4] = 0.5   # to state 5\n",
    "P_c[9,5] = 0.5   # to state 6\n",
    "\n",
    "# state 11 -> 7\n",
    "P_c[10,6] = 1.0\n",
    "\n",
    "# state 12 -> 8\n",
    "P_c[11,7] = 1.0\n",
    "\n",
    "# state 13 -> 9\n",
    "P_c[12,8] = 1.0\n",
    "\n",
    "# state 14: teleport to 12\n",
    "P_c[13,11] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06611b9b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5d597fed3b534c7a43d014ba9a22aef",
     "grade": true,
     "grade_id": "cell-5fff9e8634cf98d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac3f9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c216b7bafbc82443ed56ad2ebdbee10",
     "grade": false,
     "grade_id": "cell-7a2d9ab430c42144",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, compute the state value function v for all states. Call the vector of values v_c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "751edc66",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e40e8da44f86d91d9a29df5d6d63b242",
     "grade": false,
     "grade_id": "cell-4d77ac0e03f34933",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define v\n",
    "v_c = v_c = np.linalg.inv(ident - gamma * P_c) @ r_c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2549a85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cad98d0a262e1cfbc961a66148049a91",
     "grade": true,
     "grade_id": "cell-e2c922a7d440129a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell (Run this cell!)\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1995baee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f941e34fe34e2cb99d0eb79efbde235f",
     "grade": false,
     "grade_id": "cell-95c38271e02c61a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.09663143, 17.99645414, 18.94363594, 17.99645414],\n",
       "       [16.24179986,         nan, 17.99645414, 17.09663143],\n",
       "       [14.67751151, 15.45001212, 16.26317065, 16.24179986],\n",
       "       [13.94363594, 14.67751151,         nan, 15.24645414]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to better visualize v_b in terms of grid neighboring state values.\n",
    "v_visual = np.concatenate((v_c[0:5],[np.nan],v_c[5:13],[np.nan],v_c[13:14]))\n",
    "v_visual.reshape((4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd2679",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a24a51ae6c55ed3f3075c351e8c4440",
     "grade": false,
     "grade_id": "cell-3b2bf2b6d103b7ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which of the follow grids with arrows represents the greedy policy at this point? The answer is either 1, 2, 3, or 4. Store your answer in the next cell in a variable called <code>policy_c</code>.\n",
    "\n",
    "<br>\n",
    "<img src=\"four_policies_round2.png\" width=\"700\"> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca8e6cc9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8d5607ee0c1e9744e82bf2c78f8e52c",
     "grade": false,
     "grade_id": "cell-b5e4d74952314de4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "policy_c = 2\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "feb70fbd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc9015520e6d0cf956383be4a3399d7a",
     "grade": true,
     "grade_id": "cell-ae8399c16f7e36f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test Cell (Run this cell!)\n",
    "# NOTE: This cell contains hidden tests. You will not see whether you passed these tests until you submit your assignment.\n",
    "# Any cell labeled \"Hidden Test Cell\" MAY have hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa902e75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f14d81282b0d2fd1c0243a56d2bf3d32",
     "grade": false,
     "grade_id": "cell-d7b238c2163a64ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is the end of this lab. Note that we have not necessarily found Marvin's optimal policy yet. We need to continuing updating the rewards vector, the transition probability matrix, and ultimately the state value function until the values of the state value function have stabilized. In order to do this, it would be beneficial to express the states as state $(1,1)$ through state $(4,4)$ as opposed to $1$ through $14$, to store the state value and rewards vectors as matrices, and to automate the policy finding step. This last part is non-trivial from a coding persepctive since each cell could contain different numbers of arrows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
